{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\miniconda3\\envs\\partmc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Function to set random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the random seed for reproducibility across numpy, random, and PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - seed (int): The seed value to ensure reproducibility.\n",
    "    \"\"\"\n",
    "    # Set seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set seed for PyTorch (CPU and GPU)\n",
    "    torch.manual_seed(seed)  # CPU\n",
    "    if torch.cuda.is_available():  # GPU\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Ensure deterministic behavior in PyTorch\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the random seed to ensure reproducibility\n",
    "seed = 42  # Seed value for reproducibility\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['O3 (ppb)', 'CO (ppb)', 'NO (ppb)', 'NOx (ppb)',\n",
    "        'ETH (ppb)', 'TOL(ppb)', 'XYL (ppb)', 'ALD2 (ppb)',\n",
    "       'AONE (ppb)', 'PAR (ppb)', 'OLET (ppb)', 'Temperature(K)', 'RH',\n",
    "       'BC (ug/m3)', 'OA (ug/m3)', 'NH4 (ug/m3)', 'NO3 (ug/m3)', 'SO4 (ug/m3)']\n",
    "\n",
    "\n",
    "# Load the dataset used for training the original model for Normalizing\n",
    "partmc_train_data = pd.read_csv('../Data/PartMC_data/PartMC_train.csv')\n",
    "X_train = partmc_train_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 11:53:10,968] A new study created in memory with name: no-name-d2ad2d71-8217-4236-80c9-e5e9cc68089c\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\862956076.py:70: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\862956076.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # L2 正则化权重\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\862956076.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 11:54:14,661] Trial 0 finished with value: 0.0022644151467829943 and parameters: {'lr': 2.183952325342162e-05, 'num_frozen_blocks': 13, 'weight_decay': 1.7872169984104416e-05}. Best is trial 0 with value: 0.0022644151467829943.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\862956076.py:70: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\862956076.py:72: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # L2 正则化权重\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\862956076.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 11:55:00,028] Trial 1 finished with value: 0.0023497450165450573 and parameters: {'lr': 2.11595237560078e-05, 'num_frozen_blocks': 14, 'weight_decay': 5.42476693840783e-05}. Best is trial 0 with value: 0.0022644151467829943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lr': 2.183952325342162e-05, 'num_frozen_blocks': 13, 'weight_decay': 1.7872169984104416e-05}\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "megapoli_train_data = pd.read_csv('../Data/MEGAPOLI_data/MEGAPOLI_Marine_train_25%.csv') # e.g. Use 50% fine-tuning training dataset to fine-tune foundation model\n",
    "megapoli_test_data = pd.read_csv('../Data/MEGAPOLI_data/MEGAPOLI_Marine_test_50%.csv')\n",
    "\n",
    "def load_data(megapoli_train_data, megapoli_test_data):\n",
    "\n",
    "    # Prepare MEGAPOLI data\n",
    "    X_megapoli_train = megapoli_train_data[features]\n",
    "    y_megapoli_train = megapoli_train_data.iloc[:, 23]\n",
    "    X_megapoli_test = megapoli_test_data[features]\n",
    "    y_megapoli_test = megapoli_test_data.iloc[:, 23]\n",
    "\n",
    "    # Standardize the data using the scaler from the original model's training data\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train2 = scaler_X.fit_transform(X_train)  #  Fit on the original training data, X_train2 ensures no need to reload the original dataset (PartMC)\n",
    "    X_megapoli_train = scaler_X.transform(X_megapoli_train)\n",
    "    X_megapoli_test = scaler_X.transform(X_megapoli_test)\n",
    "    return X_megapoli_train, y_megapoli_train, X_megapoli_test, y_megapoli_test\n",
    "\n",
    "\n",
    "# Define the ResNet-like model architecture\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_features, num_blocks, hidden_size):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.fc_in = nn.Linear(in_features, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResNetBlock(hidden_size) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc_in(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.blocks(out)\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "    \n",
    "# Define the Optuna objective function for hyperparameter optimization\n",
    "def objective(trial):\n",
    "    X_megapoli_train, y_megapoli_train, X_megapoli_test, y_megapoli_test = load_data(megapoli_train_data, megapoli_test_data)\n",
    "    \n",
    "    X_megapoli_train_tensor = torch.tensor(X_megapoli_train, dtype=torch.float32)\n",
    "    y_megapoli_train_tensor = torch.tensor(y_megapoli_train, dtype=torch.float32)\n",
    "    X_megapoli_test_tensor = torch.tensor(X_megapoli_test, dtype=torch.float32)\n",
    "    y_megapoli_test_tensor = torch.tensor(y_megapoli_test, dtype=torch.float32)\n",
    "\n",
    "    megapoli_train_dataset = TensorDataset(X_megapoli_train_tensor, y_megapoli_train_tensor)\n",
    "    train_loader = DataLoader(megapoli_train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    input_size = X_megapoli_train_tensor.shape[1]\n",
    "    num_blocks = 15\n",
    "    hidden_size = 512\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    num_frozen_blocks = trial.suggest_int(\"num_frozen_blocks\", 10, 14)  # 选择冻结层数\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # L2 正则化权重\n",
    "    \n",
    "    model = ResNet(input_size, num_blocks, hidden_size)\n",
    "    model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
    "    \n",
    "    # 冻结部分层\n",
    "    for i, block in enumerate(model.blocks):\n",
    "        if i < num_frozen_blocks:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    num_epochs = 20\n",
    "    best_epoch = 0\n",
    "    best_mse = float('inf')\n",
    "    no_improve = 0\n",
    "    patience = 4\n",
    "    best_weights = None\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.view(-1), y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(X_megapoli_test_tensor).view(-1).numpy()\n",
    "            y_true = y_megapoli_test_tensor.numpy()\n",
    "            test_mse = mean_squared_error(y_true, predictions)\n",
    "\n",
    "        if test_mse < best_mse:\n",
    "            best_mse = test_mse\n",
    "            best_weights = model.state_dict().copy()\n",
    "            no_improve = 0\n",
    "        else: \n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    return best_mse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=2)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 11:57:30,973] A new study created in memory with name: no-name-8ff98adc-43bd-449d-a86f-76b3f71b21a8\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 11:58:12,429] Trial 0 finished with value: 0.0021405660081654787 and parameters: {'lr': 5.0403738262477035e-05, 'num_frozen_blocks': 14, 'weight_decay': 1.3084335031109447e-05}. Best is trial 0 with value: 0.0021405660081654787.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 11:59:11,346] Trial 1 finished with value: 0.0031416115816682577 and parameters: {'lr': 1.5396896176797261e-06, 'num_frozen_blocks': 13, 'weight_decay': 0.0029624477141339187}. Best is trial 0 with value: 0.0021405660081654787.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:00:12,177] Trial 2 finished with value: 0.003011728171259165 and parameters: {'lr': 1.7373142407675945e-06, 'num_frozen_blocks': 13, 'weight_decay': 0.00027918022941488224}. Best is trial 0 with value: 0.0021405660081654787.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:01:35,251] Trial 3 finished with value: 0.00251195952296257 and parameters: {'lr': 6.680208017417015e-06, 'num_frozen_blocks': 10, 'weight_decay': 0.00015161731162639789}. Best is trial 0 with value: 0.0021405660081654787.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:03:11,154] Trial 4 finished with value: 0.00198916532099247 and parameters: {'lr': 4.167017271524157e-05, 'num_frozen_blocks': 10, 'weight_decay': 0.0007837907516840837}. Best is trial 4 with value: 0.00198916532099247.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:03:36,894] Trial 5 finished with value: 0.0018259858479723334 and parameters: {'lr': 0.00054484704122313, 'num_frozen_blocks': 13, 'weight_decay': 0.0016129152529076056}. Best is trial 5 with value: 0.0018259858479723334.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:04:31,693] Trial 6 finished with value: 0.0026043206453323364 and parameters: {'lr': 7.175248524743039e-06, 'num_frozen_blocks': 12, 'weight_decay': 0.0012028119700163704}. Best is trial 5 with value: 0.0018259858479723334.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:05:05,284] Trial 7 finished with value: 0.0018110312521457672 and parameters: {'lr': 0.0005942582540496458, 'num_frozen_blocks': 13, 'weight_decay': 0.00046023135879256035}. Best is trial 7 with value: 0.0018110312521457672.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:06:04,280] Trial 8 finished with value: 0.0017210706137120724 and parameters: {'lr': 0.00035645768678550034, 'num_frozen_blocks': 11, 'weight_decay': 2.0352238770974544e-05}. Best is trial 8 with value: 0.0017210706137120724.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:07:43,133] Trial 9 finished with value: 0.0017707409569993615 and parameters: {'lr': 0.00010203136976341329, 'num_frozen_blocks': 10, 'weight_decay': 0.0005818370822736641}. Best is trial 8 with value: 0.0017210706137120724.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:08:09,724] Trial 10 finished with value: 0.00204155663959682 and parameters: {'lr': 0.00018865055653377862, 'num_frozen_blocks': 11, 'weight_decay': 1.0573973197620354e-05}. Best is trial 8 with value: 0.0017210706137120724.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:08:49,549] Trial 11 finished with value: 0.0020762586500495672 and parameters: {'lr': 0.00013611093583071768, 'num_frozen_blocks': 11, 'weight_decay': 8.409253435907944e-05}. Best is trial 8 with value: 0.0017210706137120724.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:09:24,579] Trial 12 finished with value: 0.0018129718955606222 and parameters: {'lr': 0.00017673626936285815, 'num_frozen_blocks': 11, 'weight_decay': 5.7110016411100384e-05}. Best is trial 8 with value: 0.0017210706137120724.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:09:54,675] Trial 13 finished with value: 0.0014531334163621068 and parameters: {'lr': 0.0009968782376990628, 'num_frozen_blocks': 10, 'weight_decay': 0.005903513861765239}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:10:33,740] Trial 14 finished with value: 0.0015983382472768426 and parameters: {'lr': 0.0007632101647606045, 'num_frozen_blocks': 11, 'weight_decay': 0.008868231356107403}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:11:13,311] Trial 15 finished with value: 0.0017482794355601072 and parameters: {'lr': 0.0008899039274135407, 'num_frozen_blocks': 12, 'weight_decay': 0.009679312059654862}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:12:40,551] Trial 16 finished with value: 0.002484551863744855 and parameters: {'lr': 1.0220252249407264e-05, 'num_frozen_blocks': 10, 'weight_decay': 0.005488682689177917}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:13:50,010] Trial 17 finished with value: 0.0018019602866843343 and parameters: {'lr': 0.0003113157282252384, 'num_frozen_blocks': 11, 'weight_decay': 0.0032290499341603297}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:14:37,325] Trial 18 finished with value: 0.001635002321563661 and parameters: {'lr': 0.0009618666582491963, 'num_frozen_blocks': 12, 'weight_decay': 0.009302223969663168}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:16:23,838] Trial 19 finished with value: 0.0017896884819492698 and parameters: {'lr': 8.232067091930714e-05, 'num_frozen_blocks': 10, 'weight_decay': 0.0029643729401387098}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:17:35,519] Trial 20 finished with value: 0.002215087413787842 and parameters: {'lr': 2.381365857286354e-05, 'num_frozen_blocks': 12, 'weight_decay': 0.005434046028449069}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:18:07,169] Trial 21 finished with value: 0.001610466162674129 and parameters: {'lr': 0.0008615910246644001, 'num_frozen_blocks': 12, 'weight_decay': 0.00910469267544492}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:18:54,228] Trial 22 finished with value: 0.0020376648753881454 and parameters: {'lr': 0.0003335497849526474, 'num_frozen_blocks': 11, 'weight_decay': 0.005339964363008842}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:19:40,954] Trial 23 finished with value: 0.0016894956352189183 and parameters: {'lr': 0.0005460590749030694, 'num_frozen_blocks': 12, 'weight_decay': 0.001992570132323183}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:20:17,471] Trial 24 finished with value: 0.0017576749669387937 and parameters: {'lr': 0.0009153294347183335, 'num_frozen_blocks': 11, 'weight_decay': 0.009444242558360051}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:21:08,214] Trial 25 finished with value: 0.0018504494801163673 and parameters: {'lr': 0.0002566554292347989, 'num_frozen_blocks': 10, 'weight_decay': 0.004752323022965555}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:21:35,921] Trial 26 finished with value: 0.0021448137704283 and parameters: {'lr': 0.0005555673684174452, 'num_frozen_blocks': 14, 'weight_decay': 0.0011383513224166584}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:22:12,246] Trial 27 finished with value: 0.001746326219290495 and parameters: {'lr': 0.0003961347513371288, 'num_frozen_blocks': 12, 'weight_decay': 0.0020521332401608155}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:23:28,349] Trial 28 finished with value: 0.002294279867783189 and parameters: {'lr': 2.0072071153212174e-05, 'num_frozen_blocks': 11, 'weight_decay': 0.003900585156861541}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:24:20,944] Trial 29 finished with value: 0.0022184469271451235 and parameters: {'lr': 8.705415810492258e-05, 'num_frozen_blocks': 10, 'weight_decay': 0.006991301184922522}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:25:12,759] Trial 30 finished with value: 0.0021201693452894688 and parameters: {'lr': 6.267372990561555e-05, 'num_frozen_blocks': 14, 'weight_decay': 0.002418824755246983}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:25:44,871] Trial 31 finished with value: 0.0018116513965651393 and parameters: {'lr': 0.0009476200838097755, 'num_frozen_blocks': 12, 'weight_decay': 0.009189614180187577}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:26:04,461] Trial 32 finished with value: 0.00201511406339705 and parameters: {'lr': 0.0007046417386894786, 'num_frozen_blocks': 12, 'weight_decay': 0.00742735732240395}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:26:30,817] Trial 33 finished with value: 0.0019575022161006927 and parameters: {'lr': 0.00022359448027772685, 'num_frozen_blocks': 13, 'weight_decay': 0.003941313930293166}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:27:06,290] Trial 34 finished with value: 0.00165423599537462 and parameters: {'lr': 0.000992824448912287, 'num_frozen_blocks': 12, 'weight_decay': 0.006661244889434315}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:27:46,746] Trial 35 finished with value: 0.0032926693093031645 and parameters: {'lr': 1.1065855202481365e-06, 'num_frozen_blocks': 13, 'weight_decay': 0.009921278668494135}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:28:35,517] Trial 36 finished with value: 0.0017472202889621258 and parameters: {'lr': 0.0004433204126817313, 'num_frozen_blocks': 11, 'weight_decay': 0.0001653476075596841}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:29:30,113] Trial 37 finished with value: 0.0016436405712738633 and parameters: {'lr': 0.0006816855897913871, 'num_frozen_blocks': 13, 'weight_decay': 0.0014165472734363413}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:30:16,670] Trial 38 finished with value: 0.0016884817741811275 and parameters: {'lr': 0.0004222489625124244, 'num_frozen_blocks': 12, 'weight_decay': 0.0009268473373979391}. Best is trial 13 with value: 0.0014531334163621068.\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)  # Optimize L2 regularization\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_69696\\3903522669.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
      "[I 2025-01-30 12:30:45,180] Trial 39 finished with value: 0.0016614742344245315 and parameters: {'lr': 0.0006428793636117002, 'num_frozen_blocks': 10, 'weight_decay': 0.0029100289781692277}. Best is trial 13 with value: 0.0014531334163621068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lr': 0.0009968782376990628, 'num_frozen_blocks': 10, 'weight_decay': 0.005903513861765239}\n"
     ]
    }
   ],
   "source": [
    "# Define the Optuna objective function for hyperparameter optimization\n",
    "def objective(trial):\n",
    "    X_megapoli_train, y_megapoli_train, X_megapoli_test, y_megapoli_test = load_data(megapoli_train_data, megapoli_test_data)\n",
    "    \n",
    "    X_megapoli_train_tensor = torch.tensor(X_megapoli_train, dtype=torch.float32)\n",
    "    y_megapoli_train_tensor = torch.tensor(y_megapoli_train, dtype=torch.float32)\n",
    "    X_megapoli_test_tensor = torch.tensor(X_megapoli_test, dtype=torch.float32)\n",
    "    y_megapoli_test_tensor = torch.tensor(y_megapoli_test, dtype=torch.float32)\n",
    "\n",
    "    megapoli_train_dataset = TensorDataset(X_megapoli_train_tensor, y_megapoli_train_tensor)\n",
    "    train_loader = DataLoader(megapoli_train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    input_size = X_megapoli_train_tensor.shape[1]\n",
    "    num_blocks = 15\n",
    "    hidden_size = 512\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-3)    \n",
    "    num_frozen_blocks = trial.suggest_int(\"num_frozen_blocks\", 10, 14)  # Optimize number of frozen layers\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3)  # Optimize L2 regularization\n",
    "    \n",
    "    model = ResNet(input_size, num_blocks, hidden_size)\n",
    "    model.load_state_dict(torch.load('../Model/Foundation_Model.pth'))\n",
    "    \n",
    "    # Freeze the selected number of layers\n",
    "    for i, block in enumerate(model.blocks):\n",
    "        if i < num_frozen_blocks:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    num_epochs = 20\n",
    "    best_mse = float('inf')\n",
    "    no_improve = 0\n",
    "    patience = 4\n",
    "    best_weights = None\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.view(-1), y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(X_megapoli_test_tensor).view(-1).numpy()\n",
    "            y_true = y_megapoli_test_tensor.numpy()\n",
    "            test_mse = mean_squared_error(y_true, predictions)\n",
    "\n",
    "        if test_mse < best_mse:\n",
    "            best_mse = test_mse\n",
    "            best_weights = model.state_dict().copy()\n",
    "            no_improve = 0\n",
    "        else: \n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    return best_mse\n",
    "\n",
    "# Run Optuna hyperparameter optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "# Output best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "partmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
